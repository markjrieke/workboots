---
title: "Getting Started"
output: rmarkdown::html_vignette
author: "Mark Rieke"
date: "`r Sys.Date()`"
vignette: >
  %\VignetteIndexEntry{Getting Started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE,
  fig.width = 5
)

ggplot2::theme_set(
  ggplot2::theme_minimal(base_size = 8) +
    ggplot2::theme(plot.title.position = "plot",
                   plot.background = ggplot2::element_rect(fill = "white", color = "white"))
)
```

When creating models, the range of expected outcomes is often just as important as the most likely outcome. For example, a prediction that a house will have a price of \$250,000 +/- \$10,000 has a vastly different interpretation than a prediction that a house will have a price of \$250,000 +/- \$50,000! Some models (like linear models) can output both point predictions and confidence intervals (*N.B. this is actually different than a prediction interval*) around each prediction but other --- often more powerful --- models can only output point predictions. 

This is where [bootstrap resampling](https://rsample.tidymodels.org/reference/bootstraps.html) can help! Creating `n` resamples of the original dataset allows us to create `n` models --- one for each resample. These many models can then be used to predict on new data and create a distribution of expected outcomes for each prediction. 

`{workboots}` is a tidy implementation of this solution written around the core function `predict_boots()`. Pass an untrained workflow object to `predict_boots()` to return a tibble of nested predictions for each observation. 

## Generating point predictions

Let's work through a motivating example of predicting a penguin's weight (`body_mass_g`) from other characteristics using the Palmer Penguins dataset.

```{r}
library(tidymodels)

data("penguins")

penguins <- 
  penguins %>%
  drop_na()

penguins
```

[XGBoost](https://xgboost.readthedocs.io/en/stable/) is a powerful model architecture, but only can generate point predictions. To generate single estimates for each penguin's weight, we can create and fit a workflow (some useful resources for how to use `{tidymodels}` include the [tidymodels package site](https://www.tidymodels.org/) and the book [Tidy Modeling with R](https://www.tmwr.org/)). 

```{r}
# split data into training and testing sets
set.seed(123)
penguins_split <- initial_split(penguins)
penguins_test <- testing(penguins_split)
penguins_train <- training(penguins_split)

# create a workflow
penguins_wf <-
  workflow() %>%
  
  # add preprocessing steps
  add_recipe(
    recipe(body_mass_g ~ ., data = penguins_train) %>%
      step_dummy(all_nominal_predictors())
  ) %>%
  
  # add xgboost model specification
  add_model(
    boost_tree("regression") %>% set_engine("xgboost")
  )

# fit to training data & predict on test data
set.seed(234)
penguins_preds <-
  penguins_wf %>%
  fit(penguins_train) %>%
  predict(penguins_test)
```

As mentioned above, XGBoost models only generate point predictions.

```{r}
penguins_preds %>%
  bind_cols(penguins_test) %>%
  ggplot(aes(x = body_mass_g,
             y = .pred)) +
  geom_point() +
  geom_segment(aes(x = 3000, xend = 6000,
                   y = 3000, yend = 6000),
               linetype = "dashed",
               color = "gray") +
  labs(title = "Single XGBoost Model Predictions")
```

## Using `{workboots}` to Generate Prediction Intervals

With `{workboots}`, however, we can generate a prediction distribution for each penguin's weight in the test set! To do so, we'll pass our workflow to `predict_boots()`, which will return a nested tibble with a set of predictions for each penguin in the `penguins_test` set. 

```{r}
library(workboots)

# create 100 models from bootstrap resamples and make predictions on the test set
set.seed(345)
penguins_preds_boot <- 
  penguins_wf %>%
  predict_boots(
    n = 100,
    training_data = penguins_train,
    new_data = penguins_test
  )

penguins_preds_boot
```

From each set of nexted predictions, we can summarise with a lower and upper bound of our prediction interval (this uses the [`quantile()`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/quantile) function under the hood). 

```{r}
penguins_preds_boot %>%
  summarise_predictions()
```

This allows us to include a prediction interval along with our point predictions!

```{r}
penguins_preds_boot %>%
  summarise_predictions() %>%
  bind_cols(penguins_test) %>%
  ggplot(aes(x = body_mass_g,
             y = .pred,
             ymin = .pred_lower,
             ymax = .pred_upper)) +
  geom_abline(linetype = "dashed",
              color = "gray") + 
  geom_errorbar(alpha = 0.5) +
  geom_point(alpha = 0.5) +
  labs(title = "XGBoost Model Prediction Intervals from Bootstrap Resampling",
       subtitle = "Error bars represent the 2.5/97.5% quantiles")
```


